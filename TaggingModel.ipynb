{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0hvoMqoHh5K"
      },
      "outputs": [],
      "source": [
        "##Importing dataset and splitting data\n",
        "\n",
        "#Importing Libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Importing csv file\n",
        "df = pd.read_csv('CleanedData_Majoriti.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#for text pre-processing\n",
        "import re, string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "#for model-building\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "# bag of words\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#for word embedding\n",
        "import gensim\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN4qlmXKH3I0",
        "outputId": "454b4cc9-7d12-4703-ce06-21807096f1cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec.load(\"word2vec.model\")\n",
        "model.wv[\"komputer\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ3GHsAjlzH3",
        "outputId": "e4cedec6-2365-418c-9b9c-b75dda988ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.0030890e+00,  1.1668658e+00,  3.1730196e+00, -2.3261182e+00,\n",
              "        1.7651902e+00, -3.8568044e-01, -2.5092115e+00, -7.9701048e-01,\n",
              "       -2.8481660e+00,  5.3194456e+00,  1.2957495e+00,  1.2588059e+00,\n",
              "       -8.1049585e-01, -8.3724791e-01, -4.8270416e+00,  2.3097040e-01,\n",
              "        9.9782985e-01,  1.5582583e-03,  8.1228590e-01, -2.1840425e+00,\n",
              "        2.6374786e+00,  2.4148333e+00, -2.0726845e+00, -8.4248900e-01,\n",
              "        5.8088827e-01, -1.4424770e-01,  5.0732118e-01, -1.4858186e+00,\n",
              "        3.8093214e+00,  2.0468314e+00,  7.5959480e-01, -1.3071066e-01,\n",
              "       -3.1043667e-01,  2.2953562e-01,  2.0790126e+00,  2.3654203e+00,\n",
              "       -1.7722260e+00,  8.2322367e-02, -6.7984858e+00, -3.8807423e+00,\n",
              "       -1.4320104e+00,  5.1404184e-01, -2.7231383e+00,  3.2866046e-01,\n",
              "        3.8763020e+00,  8.9822792e-02,  2.5025206e+00, -2.6773622e+00,\n",
              "       -8.9282674e-01, -7.6355845e-01, -2.3466096e+00,  4.4702730e+00,\n",
              "        1.4850051e+00, -2.8918631e+00, -8.7402767e-01, -8.8080084e-01,\n",
              "        7.7748197e-01, -1.2890898e-01, -2.5862670e+00, -3.7837203e+00,\n",
              "       -3.9419646e+00,  2.8298676e+00,  6.3861694e+00, -1.4443297e+00,\n",
              "       -8.6938161e-01,  9.9382973e-01, -4.8960856e-01,  8.0518079e-01,\n",
              "        2.8524354e+00, -2.2833035e+00, -1.3551576e+00, -1.8983614e+00,\n",
              "        4.0697932e-01,  4.0810637e+00,  1.4819486e-01, -1.4476092e+00,\n",
              "        9.5482212e-01,  1.2460886e+00,  4.1558781e+00, -2.1935727e-01,\n",
              "       -3.3462138e+00,  2.0302138e+00, -1.6845356e+00,  1.1381334e+00,\n",
              "       -9.9119253e-02,  1.3716679e+00, -3.5444283e+00, -4.1771162e-01,\n",
              "        1.5944801e-01, -2.6358263e+00,  8.2564211e-01, -1.0948304e+00,\n",
              "       -1.2239230e+00,  2.0061197e+00,  4.7136387e-01, -2.0250106e+00,\n",
              "        5.1553516e+00, -2.4004819e+00, -3.8177459e+00, -4.5956191e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SPLITTING THE TRAINING DATASET INTO TRAIN AND TEST\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[\"Text\"],df[\"Target\"],test_size=0.3,random_state=0)\n",
        "#Word2Vec\n",
        "# Word2Vec runs on tokenized sentences\n",
        "X_train_tok= [nltk.word_tokenize(i) for i in X_train]\n",
        "X_test_tok= [nltk.word_tokenize(i) for i in X_test]"
      ],
      "metadata": {
        "id": "yl-tBjkPHo6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = set(model.wv.index_to_key )\n",
        "X_train_vect = np.array([np.array([model.wv[i] for i in ls if i in words])\n",
        "                         for ls in X_train_tok])\n",
        "X_test_vect = np.array([np.array([model.wv[i] for i in ls if i in words])\n",
        "                         for ls in X_test_tok])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCKV7GtXoFxt",
        "outputId": "9e40f527-4842-44a3-d328-d5371f6bc47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-130-2bab746a38ba>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X_train_vect = np.array([np.array([model.wv[i] for i in ls if i in words])\n",
            "<ipython-input-130-2bab746a38ba>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X_test_vect = np.array([np.array([model.wv[i] for i in ls if i in words])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute sentence vectors by averaging the word vectors for the words contained in the sentence\n",
        "X_train_vect_avg = []\n",
        "for v in X_train_vect:\n",
        "    if v.size:\n",
        "        X_train_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_train_vect_avg.append(np.zeros(100, dtype=float))\n",
        "\n",
        "X_test_vect_avg = []\n",
        "for v in X_test_vect:\n",
        "    if v.size:\n",
        "        X_test_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_test_vect_avg.append(np.zeros(100, dtype=float))"
      ],
      "metadata": {
        "id": "6HmkAao1oXJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Are our sentence vector lengths consistent?\n",
        "for i, v in enumerate(X_train_vect_avg):\n",
        "    print(len(X_train.iloc[i]), len(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in9RjqCEobb3",
        "outputId": "f4646c21-3530-420b-e49f-cd9d4568572a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36 100\n",
            "77 100\n",
            "63 100\n",
            "52 100\n",
            "80 100\n",
            "47 100\n",
            "52 100\n",
            "179 100\n",
            "96 100\n",
            "82 100\n",
            "42 100\n",
            "64 100\n",
            "27 100\n",
            "79 100\n",
            "63 100\n",
            "79 100\n",
            "36 100\n",
            "84 100\n",
            "27 100\n",
            "32 100\n",
            "26 100\n",
            "113 100\n",
            "22 100\n",
            "68 100\n",
            "47 100\n",
            "89 100\n",
            "75 100\n",
            "53 100\n",
            "65 100\n",
            "162 100\n",
            "91 100\n",
            "14 100\n",
            "81 100\n",
            "25 100\n",
            "40 100\n",
            "28 100\n",
            "26 100\n",
            "85 100\n",
            "73 100\n",
            "20 100\n",
            "38 100\n",
            "14 100\n",
            "100 100\n",
            "4 100\n",
            "67 100\n",
            "99 100\n",
            "10 100\n",
            "44 100\n",
            "34 100\n",
            "79 100\n",
            "28 100\n",
            "46 100\n",
            "38 100\n",
            "45 100\n",
            "85 100\n",
            "86 100\n",
            "14 100\n",
            "69 100\n",
            "24 100\n",
            "73 100\n",
            "111 100\n",
            "83 100\n",
            "98 100\n",
            "39 100\n",
            "50 100\n",
            "76 100\n",
            "36 100\n",
            "118 100\n",
            "59 100\n",
            "21 100\n",
            "83 100\n",
            "46 100\n",
            "35 100\n",
            "78 100\n",
            "25 100\n",
            "67 100\n",
            "135 100\n",
            "41 100\n",
            "49 100\n",
            "29 100\n",
            "106 100\n",
            "59 100\n",
            "21 100\n",
            "47 100\n",
            "91 100\n",
            "37 100\n",
            "19 100\n",
            "77 100\n",
            "46 100\n",
            "18 100\n",
            "93 100\n",
            "89 100\n",
            "28 100\n",
            "49 100\n",
            "12 100\n",
            "80 100\n",
            "49 100\n",
            "87 100\n",
            "84 100\n",
            "20 100\n",
            "55 100\n",
            "45 100\n",
            "29 100\n",
            "68 100\n",
            "39 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate and fit a basic Random Forest model on top of the vectors\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "rf_model = rf.fit(X_train_vect_avg, y_train.values.ravel())\n",
        "\n",
        "\n",
        "\n",
        "#FITTING THE CLASSIFICATION MODEL using SVM(W2v)\n",
        "from sklearn import svm\n",
        "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto',probability=True)\n",
        "\n",
        "\n",
        "\n",
        "S=SVM.fit(X_train_vect_avg, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "jtcTMbUGoj13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained model to make predictions on the test data\n",
        "y_pred = rf_model.predict(X_test_vect_avg)"
      ],
      "metadata": {
        "id": "_duPSwCao8RX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
        "    round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XKL1SxhpF9w",
        "outputId": "9941786f-d0a6-4353-cc57-65b404ccac5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.824 / Recall: 0.7 / Accuracy: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tf-Idf\n",
        "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
        "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "#Bow\n",
        "bow_vectorizer = CountVectorizer()\n",
        "X_train_vectors_bow = bow_vectorizer.fit_transform(X_train)\n",
        "X_test_vectors_bow = bow_vectorizer.transform(X_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#building Word2Vec model\n",
        "class MeanEmbeddingVectorizer(object):\n",
        "    def __init__(self, word2vec):\n",
        "        self.word2vec = word2vec\n",
        "        # if a text is empty we should return a vector of zeros\n",
        "        # with the same dimensionality as all the other vectors\n",
        "        self.dim = len(next(iter(word2vec.values())))\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        return np.array([\n",
        "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
        "                    or [np.zeros(self.dim)], axis=0)\n",
        "            for words in X\n",
        "        ])\n",
        "df['clean_text_tok']=[nltk.word_tokenize(i) for i in df['Text']]\n",
        "model = Word2Vec(df['clean_text_tok'],min_count=1)\n",
        "w2v = dict(zip(model.wv.index_to_key, model.wv.vectors))\n",
        "\n",
        "modelw = MeanEmbeddingVectorizer(w2v)\n",
        "\n",
        "\n",
        "\n",
        "# converting text to numerical data using Word2Vec\n",
        "X_train_vectors_w2v = modelw.transform(X_train_tok)\n",
        "X_val_vectors_w2v = modelw.transform(X_test_tok)"
      ],
      "metadata": {
        "id": "u9zd9J-BIFym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FITTING THE CLASSIFICATION MODEL using SVM(W2v)\n",
        "from sklearn import svm\n",
        "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto',probability=True)\n",
        "\n",
        "\n",
        "\n",
        "SVM.fit(X_train_vectors_w2v, y_train)\n",
        "\n",
        "#lr_tfidf=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
        "#lr_tfidf.fit(X_train_vectors_tfidf, y_train)\n",
        "#Predict y value for test dataset\n",
        "y_predict = SVM.predict(X_val_vectors_w2v)\n",
        "y_prob = SVM.predict_proba(X_val_vectors_w2v)[:,1]\n",
        "print(classification_report(y_test,y_predict))\n",
        "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print('AUC:', roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhmzKp4VpTq0",
        "outputId": "9c95a74b-ccf3-4364-ace8-bf063ddfac37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        25\n",
            "           1       0.44      1.00      0.62        20\n",
            "\n",
            "    accuracy                           0.44        45\n",
            "   macro avg       0.22      0.50      0.31        45\n",
            "weighted avg       0.20      0.44      0.27        45\n",
            "\n",
            "Confusion Matrix: [[ 0 25]\n",
            " [ 0 20]]\n",
            "AUC: 0.346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest using tf-idf\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train_vectors_tfidf, y_train)\n",
        "#Predict y value for test dataset\n",
        "y_predict = rf.predict(X_test_vectors_tfidf)\n",
        "y_prob = rf.predict_proba(X_test_vectors_tfidf)[:,1]\n",
        "print(classification_report(y_test,y_predict))\n",
        "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print('AUC:', roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnF_Q8dnren6",
        "outputId": "e9740e37-2211-40d3-81af-c19473efe759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86        25\n",
            "           1       0.84      0.80      0.82        20\n",
            "\n",
            "    accuracy                           0.84        45\n",
            "   macro avg       0.84      0.84      0.84        45\n",
            "weighted avg       0.84      0.84      0.84        45\n",
            "\n",
            "Confusion Matrix: [[22  3]\n",
            " [ 4 16]]\n",
            "AUC: 0.854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FITTING THE CLASSIFICATION MODEL using Naive Bayes(tf-idf)\n",
        "nb_tfidf = MultinomialNB()\n",
        "nb_tfidf.fit(X_train_vectors_tfidf, y_train)\n",
        "#Predict y value for test dataset\n",
        "y_predict = nb_tfidf.predict(X_test_vectors_tfidf)\n",
        "y_prob = nb_tfidf.predict_proba(X_test_vectors_tfidf)[:,1]\n",
        "print(classification_report(y_test,y_predict))\n",
        "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print('AUC:', roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgKlKAdLpzj6",
        "outputId": "ea3da9d1-8826-456a-c7fb-f0c76e207e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.68      0.74        25\n",
            "           1       0.67      0.80      0.73        20\n",
            "\n",
            "    accuracy                           0.73        45\n",
            "   macro avg       0.74      0.74      0.73        45\n",
            "weighted avg       0.75      0.73      0.73        45\n",
            "\n",
            "Confusion Matrix: [[17  8]\n",
            " [ 4 16]]\n",
            "AUC: 0.815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FITTING THE CLASSIFICATION MODEL using SVM(tf-idf)\n",
        "from sklearn import svm\n",
        "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto',probability=True)\n",
        "\n",
        "\n",
        "\n",
        "SVM.fit(X_train_vectors_tfidf, y_train)\n",
        "\n",
        "#lr_tfidf=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
        "#lr_tfidf.fit(X_train_vectors_tfidf, y_train)\n",
        "#Predict y value for test dataset\n",
        "y_predict = SVM.predict(X_test_vectors_tfidf)\n",
        "y_prob = SVM.predict_proba(X_test_vectors_tfidf)[:,1]\n",
        "print(classification_report(y_test,y_predict))\n",
        "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print('AUC:', roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzyouQuEoTR6",
        "outputId": "0fa43eca-d063-4230-ced3-d6a91e9a9aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.76      0.78        25\n",
            "           1       0.71      0.75      0.73        20\n",
            "\n",
            "    accuracy                           0.76        45\n",
            "   macro avg       0.75      0.76      0.75        45\n",
            "weighted avg       0.76      0.76      0.76        45\n",
            "\n",
            "Confusion Matrix: [[19  6]\n",
            " [ 5 15]]\n",
            "AUC: 0.831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest using BOW\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train_vectors_bow, y_train)\n",
        "#Predict y value for test dataset\n",
        "y_predict = rf.predict(X_test_vectors_bow)\n",
        "y_prob = rf.predict_proba(X_test_vectors_bow)[:,1]\n",
        "print(classification_report(y_test,y_predict))\n",
        "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print('AUC:', roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdYXjD6Xr7KG",
        "outputId": "66edd086-6b98-48ba-cf24-dba0ca5ecd62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84        25\n",
            "           1       0.80      0.80      0.80        20\n",
            "\n",
            "    accuracy                           0.82        45\n",
            "   macro avg       0.82      0.82      0.82        45\n",
            "weighted avg       0.82      0.82      0.82        45\n",
            "\n",
            "Confusion Matrix: [[21  4]\n",
            " [ 4 16]]\n",
            "AUC: 0.882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FITTING THE CLASSIFICATION MODEL using Naive Bayes(bow)\n",
        "\n",
        "nb_tfidf = MultinomialNB()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "nb_tfidf.fit(X_train_vectors_bow, y_train)\n",
        "\n",
        "#lr_tfidf=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
        "#lr_tfidf.fit(X_train_vectors_tfidf, y_train)\n",
        "#Predict y value for test dataset\n",
        "y_predict = nb_tfidf.predict(X_test_vectors_bow)\n",
        "y_prob = nb_tfidf.predict_proba(X_test_vectors_bow)[:,1]\n",
        "print(classification_report(y_test,y_predict))\n",
        "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print('AUC:', roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ghul283vK_i",
        "outputId": "a14b458a-837f-4b9c-c118-603658cd5846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.72      0.77        25\n",
            "           1       0.70      0.80      0.74        20\n",
            "\n",
            "    accuracy                           0.76        45\n",
            "   macro avg       0.76      0.76      0.76        45\n",
            "weighted avg       0.76      0.76      0.76        45\n",
            "\n",
            "Confusion Matrix: [[18  7]\n",
            " [ 4 16]]\n",
            "AUC: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FITTING THE CLASSIFICATION MODEL using SVM(bow)\n",
        "from sklearn import svm\n",
        "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto',probability=True)\n",
        "\n",
        "\n",
        "\n",
        "SVM.fit(X_train_vectors_bow, y_train)\n",
        "\n",
        "#lr_tfidf=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
        "#lr_tfidf.fit(X_train_vectors_tfidf, y_train)\n",
        "#Predict y value for test dataset\n",
        "y_predict = SVM.predict(X_test_vectors_bow)\n",
        "y_prob = SVM.predict_proba(X_test_vectors_bow)[:,1]\n",
        "print(classification_report(y_test,y_predict))\n",
        "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print('AUC:', roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fJU2Z_EQ6Rx",
        "outputId": "3dc3664b-418c-4d66-e641-a331122b5bb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84        25\n",
            "           1       0.80      0.80      0.80        20\n",
            "\n",
            "    accuracy                           0.82        45\n",
            "   macro avg       0.82      0.82      0.82        45\n",
            "weighted avg       0.82      0.82      0.82        45\n",
            "\n",
            "Confusion Matrix: [[21  4]\n",
            " [ 4 16]]\n",
            "AUC: 0.867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "YKkLWqAtkml3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('text_classifier', 'wb') as picklefile:\n",
        "    pickle.dump(SVM,picklefile)"
      ],
      "metadata": {
        "id": "X5rhHM3UkaYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('SVM_model22.pkl', 'wb') as fout:\n",
        "    pickle.dump((bow_vectorizer,SVM), fout)"
      ],
      "metadata": {
        "id": "AhOe0NzJzroO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('SVM_model22.pkl', 'rb') as f:\n",
        "    bow_vectorizer, SVM = pickle.load(f)"
      ],
      "metadata": {
        "id": "0ItDsQI40umh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving model to pickle file\n",
        "with open(\"desired-model-file-name.pkl\", \"wb\") as file: # file is a variable for storing the newly created file, it can be anything.\n",
        "    pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "fw-HRfLu9Wqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uaYBMYRhpOUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "pickle_in = open('/content/SVM_model.pkl', 'rb')\n",
        "classifier = pickle.load(pickle_in)\n",
        "\n",
        "\n",
        "flat = ['ada', 'adakah', 'adakan', 'adalah', 'adanya', 'adapun', 'agak', 'agar', 'akan', 'aku', 'akulah', 'akupun', 'al', 'alangkah', 'allah', 'amat', 'antara', 'antaramu', 'antaranya', 'apa', 'apa-apa', 'apabila', 'apakah', 'apapun', 'atas', 'atasmu', 'atasnya', 'atau', 'ataukah', 'ataupun', 'bagaimana', 'bagaimanakah', 'bagi', 'bagimu', 'baginya', 'bahawa', 'bahawasanya', 'bahkan', 'bahwa', 'banyak', 'banyaknya', 'barangsiapa', 'bawah', 'beberapa', 'begitu', 'begitupun', 'belaka', 'belum', 'belumkah', 'berada', 'berapa', 'berikan', 'beriman', 'berkenaan', 'berupa', 'beserta', 'biarpun', 'bila', 'bilakah', 'bilamana', 'bisa', 'boleh', 'bukan', 'bukankah', 'bukanlah', 'dahulu', 'dalam', 'dalamnya', 'dan', 'dapat', 'dapati', 'dapatkah', 'dapatlah', 'dari', 'daripada', 'daripadaku', 'daripadamu', 'daripadanya', 'demi', 'demikian', 'demikianlah', 'dengan', 'dengannya', 'di', 'dia', 'dialah', 'didapat', 'didapati', 'dimanakah', 'engkau', 'engkaukah', 'engkaulah', 'engkaupun', 'hai', 'hampir', 'hampir-hampir', 'hanya', 'hanyalah', 'hendak', 'hendaklah', 'hingga', 'ia', 'iaitu', 'ialah', 'ianya', 'inginkah', 'ini', 'inikah', 'inilah', 'itu', 'itukah', 'itulah', 'jadi', 'jangan', 'janganlah', 'jika', 'jikalau', 'jua', 'juapun', 'juga', 'kalau', 'kami', 'kamikah', 'kamipun', 'kamu', 'kamukah', 'kamupun', 'katakan', 'ke', 'kecuali', 'kelak', 'kembali', 'kemudian', 'kepada', 'kepadaku', 'kepadakulah', 'kepadamu', 'kepadanya', 'kepadanyalah', 'kerana', 'kerananya', 'kesan', 'ketika', 'kini', 'kita', 'ku', 'kurang', 'lagi', 'lain', 'lalu', 'lamanya', 'langsung', 'lebih', 'maha', 'mahu', 'mahukah', 'mahupun', 'maka', 'malah', 'mana', 'manakah', 'manapun', 'masih', 'masing', 'masing-masing', 'melainkan', 'memang', 'mempunyai', 'mendapat', 'mendapati', 'mendapatkan', 'mengadakan', 'mengapa', 'mengapakah', 'mengenai', 'menjadi', 'menyebabkan', 'menyebabkannya', 'mereka', 'merekalah', 'merekapun', 'meskipun', 'mu', 'nescaya', 'niscaya', 'nya', 'olah', 'oleh', 'orang', 'pada', 'padahal', 'padamu', 'padanya', 'paling', 'para', 'pasti', 'patut', 'patutkah', 'per', 'pergilah', 'perkara', 'perkaranya', 'perlu', 'pernah', 'pertama', 'pula', 'pun', 'sahaja', 'saja', 'saling', 'sama', 'sama-sama', 'samakah', 'sambil', 'sampai', 'sana', 'sangat', 'sangatlah', 'saya', 'se', 'seandainya', 'sebab', 'sebagai', 'sebagaimana', 'sebanyak', 'sebelum', 'sebelummu', 'sebelumnya', 'sebenarnya', 'secara', 'sedang', 'sedangkan', 'sedikit', 'sedikitpun', 'segala', 'sehingga', 'sejak', 'sekalian', 'sekalipun', 'sekarang', 'sekitar', 'selain', 'selalu', 'selama', 'selama-lamanya', 'seluruh', 'seluruhnya', 'sementara', 'semua', 'semuanya', 'semula', 'senantiasa', 'sendiri', 'sentiasa', 'seolah', 'seolah-olah', 'seorangpun', 'separuh', 'sepatutnya', 'seperti', 'seraya', 'sering', 'serta', 'seseorang', 'sesiapa', 'sesuatu', 'sesudah', 'sesudahnya', 'sesungguhnya', 'sesungguhnyakah', 'setelah', 'setiap', 'siapa', 'siapakah', 'sini', 'situ', 'situlah', 'suatu', 'sudah', 'sudahkah', 'sungguh', 'sungguhpun', 'supaya', 'tadinya', 'tahukah', 'tak', 'tanpa', 'tanya', 'tanyakanlah', 'tapi', 'telah', 'tentang', 'tentu', 'terdapat', 'terhadap', 'terhadapmu', 'termasuk', 'terpaksa', 'tertentu', 'tetapi', 'tiada', 'tiadakah', 'tiadalah', 'tiap', 'tiap-tiap', 'tidak', 'tidakkah', 'tidaklah', 'turut', 'untuk', 'untukmu', 'wahai', 'walau', 'walaupun', 'ya', 'yaini', 'yaitu', 'yakni', 'yang', 'la']\n",
        "\n",
        "def clean_text(tweet):\n",
        "\n",
        "  if type(tweet) == float:\n",
        "      return \"\"\n",
        "  temp = tweet.lower()\n",
        "  temp = re.sub(\"'\", \"\", temp) # to avoid removing contractions in english\n",
        "  temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp)\n",
        "  temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp)\n",
        "  temp = re.sub(r'http\\S+', '', temp)\n",
        "  temp = re.sub('[()!?]', ' ', temp)\n",
        "  temp = re.sub('negative', '', temp)\n",
        "  temp = re.sub('positive', '', temp)\n",
        "  temp = re.sub('neutral', '', temp)\n",
        "  temp = re.sub('\\[.*?\\]',' ', temp)\n",
        "  temp = re.sub(\"[^a-z0-9]\",\" \", temp)\n",
        "  temp = re.sub(r'[0-9]', '', temp)\n",
        "  temp = temp.split()\n",
        "  temp = [w for w in temp if not w in flat]\n",
        "  temp = \" \".join(word for word in temp)\n",
        "  return temp\n",
        "\n",
        "\n",
        "\n",
        "def FeatureEn(temp):\n",
        "\n",
        "  X_vector=bow_vectorizer.transform(temp)\n",
        "\n",
        "  # Making predictions\n",
        "  y_predict = classifier.predict(X_vector)\n",
        "\n",
        "  if y_predict == 0:\n",
        "    p = \"Tweet free cyberbullying\"\n",
        "\n",
        "  else:\n",
        "    p = \"Tweet contain cyberbullying\"\n",
        "  return p\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "\n",
        "  clean_text('Terima kasih Ali')\n",
        "  print(clean_text)\n",
        "  a=nltk.word_tokenize('Terima kasih Ali')\n",
        "  X_vector=bow_vectorizer.transform(a)\n",
        "  y_predict = SVM.predict_proba(X_vector)\n",
        "\n",
        "  if y_predict.any() == 0:\n",
        "    p = \"Tweet free cyberbullying\"\n",
        "\n",
        "  else:\n",
        "    p = \"Tweet contain cyberbullying\"\n",
        "\n",
        "  print(p)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP1yH3OmT13x",
        "outputId": "20f0eb21-a93a-43f4-c934-241ec10e6b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<function clean_text at 0x7b73da2f7be0>\n",
            "Tweet contain cyberbullying\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    print(temp)\n",
        "\n",
        "    te = [temp]\n",
        "    X_vector=bow_vectorizer.transform(te)\n",
        "\n",
        "\n",
        "    # Making predictions\n",
        "    y_predict = classifier.predict(X_vector)\n",
        "\n",
        "    if y_predict == 0:\n",
        "      p = \"Tweet free cyberbullying\"\n",
        "\n",
        "    else:\n",
        "      p= \"Tweet contain cyberbullying\"\n",
        "    return p"
      ],
      "metadata": {
        "id": "OccF5N8csjkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = 'bodoh pon hentak org macam ni dah kali accident anjing anjing signal pandu macam celaka'\n",
        "\n",
        "flat = ['ada', 'adakah', 'adakan', 'adalah', 'adanya', 'adapun', 'agak', 'agar', 'akan', 'aku', 'akulah', 'akupun', 'al', 'alangkah', 'allah', 'amat', 'antara', 'antaramu', 'antaranya', 'apa', 'apa-apa', 'apabila', 'apakah', 'apapun', 'atas', 'atasmu', 'atasnya', 'atau', 'ataukah', 'ataupun', 'bagaimana', 'bagaimanakah', 'bagi', 'bagimu', 'baginya', 'bahawa', 'bahawasanya', 'bahkan', 'bahwa', 'banyak', 'banyaknya', 'barangsiapa', 'bawah', 'beberapa', 'begitu', 'begitupun', 'belaka', 'belum', 'belumkah', 'berada', 'berapa', 'berikan', 'beriman', 'berkenaan', 'berupa', 'beserta', 'biarpun', 'bila', 'bilakah', 'bilamana', 'bisa', 'boleh', 'bukan', 'bukankah', 'bukanlah', 'dahulu', 'dalam', 'dalamnya', 'dan', 'dapat', 'dapati', 'dapatkah', 'dapatlah', 'dari', 'daripada', 'daripadaku', 'daripadamu', 'daripadanya', 'demi', 'demikian', 'demikianlah', 'dengan', 'dengannya', 'di', 'dia', 'dialah', 'didapat', 'didapati', 'dimanakah', 'engkau', 'engkaukah', 'engkaulah', 'engkaupun', 'hai', 'hampir', 'hampir-hampir', 'hanya', 'hanyalah', 'hendak', 'hendaklah', 'hingga', 'ia', 'iaitu', 'ialah', 'ianya', 'inginkah', 'ini', 'inikah', 'inilah', 'itu', 'itukah', 'itulah', 'jadi', 'jangan', 'janganlah', 'jika', 'jikalau', 'jua', 'juapun', 'juga', 'kalau', 'kami', 'kamikah', 'kamipun', 'kamu', 'kamukah', 'kamupun', 'katakan', 'ke', 'kecuali', 'kelak', 'kembali', 'kemudian', 'kepada', 'kepadaku', 'kepadakulah', 'kepadamu', 'kepadanya', 'kepadanyalah', 'kerana', 'kerananya', 'kesan', 'ketika', 'kini', 'kita', 'ku', 'kurang', 'lagi', 'lain', 'lalu', 'lamanya', 'langsung', 'lebih', 'maha', 'mahu', 'mahukah', 'mahupun', 'maka', 'malah', 'mana', 'manakah', 'manapun', 'masih', 'masing', 'masing-masing', 'melainkan', 'memang', 'mempunyai', 'mendapat', 'mendapati', 'mendapatkan', 'mengadakan', 'mengapa', 'mengapakah', 'mengenai', 'menjadi', 'menyebabkan', 'menyebabkannya', 'mereka', 'merekalah', 'merekapun', 'meskipun', 'mu', 'nescaya', 'niscaya', 'nya', 'olah', 'oleh', 'orang', 'pada', 'padahal', 'padamu', 'padanya', 'paling', 'para', 'pasti', 'patut', 'patutkah', 'per', 'pergilah', 'perkara', 'perkaranya', 'perlu', 'pernah', 'pertama', 'pula', 'pun', 'sahaja', 'saja', 'saling', 'sama', 'sama-sama', 'samakah', 'sambil', 'sampai', 'sana', 'sangat', 'sangatlah', 'saya', 'se', 'seandainya', 'sebab', 'sebagai', 'sebagaimana', 'sebanyak', 'sebelum', 'sebelummu', 'sebelumnya', 'sebenarnya', 'secara', 'sedang', 'sedangkan', 'sedikit', 'sedikitpun', 'segala', 'sehingga', 'sejak', 'sekalian', 'sekalipun', 'sekarang', 'sekitar', 'selain', 'selalu', 'selama', 'selama-lamanya', 'seluruh', 'seluruhnya', 'sementara', 'semua', 'semuanya', 'semula', 'senantiasa', 'sendiri', 'sentiasa', 'seolah', 'seolah-olah', 'seorangpun', 'separuh', 'sepatutnya', 'seperti', 'seraya', 'sering', 'serta', 'seseorang', 'sesiapa', 'sesuatu', 'sesudah', 'sesudahnya', 'sesungguhnya', 'sesungguhnyakah', 'setelah', 'setiap', 'siapa', 'siapakah', 'sini', 'situ', 'situlah', 'suatu', 'sudah', 'sudahkah', 'sungguh', 'sungguhpun', 'supaya', 'tadinya', 'tahukah', 'tak', 'tanpa', 'tanya', 'tanyakanlah', 'tapi', 'telah', 'tentang', 'tentu', 'terdapat', 'terhadap', 'terhadapmu', 'termasuk', 'terpaksa', 'tertentu', 'tetapi', 'tiada', 'tiadakah', 'tiadalah', 'tiap', 'tiap-tiap', 'tidak', 'tidakkah', 'tidaklah', 'turut', 'untuk', 'untukmu', 'wahai', 'walau', 'walaupun', 'ya', 'yaini', 'yaitu', 'yakni', 'yang', 'la']\n",
        "\n",
        "\n",
        "X = [X]\n",
        "X_vector=bow_vectorizer.transform(X)\n",
        "y_predict = SVM.predict(X_vector)\n",
        "y_predict\n",
        "\n",
        "if y_predict == 0:\n",
        "  print(\"Tweet free cyberbullying\")\n",
        "\n",
        "else:\n",
        "  print(\"Tweet contain cyberbullying\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycTIbIWZV0n2",
        "outputId": "6ea91166-690d-4109-875e-d57f632d8de9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet contain cyberbullying\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('Dataset#2_New.csv')\n",
        "X_test=df_test['Text']\n",
        "#converting words to numerical data using tf-idf\n",
        "X_vector=bow_vectorizer.transform(X_test)\n",
        "#use the best model to predict 'target' value for the new dataset\n",
        "y_predict = SVM.predict(X_vector)\n",
        "y_prob = SVM.predict_proba(X_vector)[:,1]\n",
        "df_test['predict_prob']= y_prob\n",
        "df_test['target']= y_predict\n",
        "final=df_test[['Text','target']].reset_index(drop=True)\n",
        "final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2366
        },
        "id": "PPJJ4Umqt_Xg",
        "outputId": "f511bdc5-fa7b-42e2-e760-df65691419df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Text  target\n",
              "0                                        polis tangkap        0\n",
              "1             kenapa lokasi kebakaran terlalu spesifik        0\n",
              "2                      menyesal tanya nak for birthday        0\n",
              "3                                           meriah tah        0\n",
              "4     asal bs kelar kerja jam sik kl baru diajak mee...       0\n",
              "...                                                 ...     ...\n",
              "1088  pengerusi th pengerusi kuil songlap akhirnya s...       1\n",
              "1089  lambang kebodohan melayu sokong ph laknat seda...       1\n",
              "1090  puak puak kerja salahkan selangkah selangor go...       1\n",
              "1091                       maaf jodoh cepat bodoh macam       1\n",
              "1092                       buat bodoh bodoh bodoh bodoh       1\n",
              "\n",
              "[1093 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-7228507c-e42f-4c90-8a82-5ac8ba6159ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>polis tangkap</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kenapa lokasi kebakaran terlalu spesifik</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>menyesal tanya nak for birthday</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>meriah tah</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>asal bs kelar kerja jam sik kl baru diajak mee...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1088</th>\n",
              "      <td>pengerusi th pengerusi kuil songlap akhirnya s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1089</th>\n",
              "      <td>lambang kebodohan melayu sokong ph laknat seda...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1090</th>\n",
              "      <td>puak puak kerja salahkan selangkah selangor go...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1091</th>\n",
              "      <td>maaf jodoh cepat bodoh macam</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1092</th>\n",
              "      <td>buat bodoh bodoh bodoh bodoh</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1093 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7228507c-e42f-4c90-8a82-5ac8ba6159ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-ee3cbaa9-dc77-4d63-9d4e-f25e5fd673da\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee3cbaa9-dc77-4d63-9d4e-f25e5fd673da')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-ee3cbaa9-dc77-4d63-9d4e-f25e5fd673da button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7228507c-e42f-4c90-8a82-5ac8ba6159ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7228507c-e42f-4c90-8a82-5ac8ba6159ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final.to_csv('Tagged_MixedNew.csv')"
      ],
      "metadata": {
        "id": "uXmn6j_Xe_14"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}